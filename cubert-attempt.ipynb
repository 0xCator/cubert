{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sigmazer/GP/cubert/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-01 17:59:14.662696: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738425554.715741  706573 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738425554.730105  706573 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-01 17:59:14.823736: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1738425558.032241  706573 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2460 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2025-02-01 17:59:19.262084: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 204931072 exceeds 10% of free system memory.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel \n",
    "\n",
    "model_path = \"claudios/cubert-20210711-Java-1024\"\n",
    "model = TFAutoModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"train_beautified.csv\")\n",
    "test_df = pd.read_csv(\"test_beautified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cubert.full_cubert_tokenizer import FullCuBertTokenizer\n",
    "from cubert import java_tokenizer\n",
    "\n",
    "fullTokenizer = FullCuBertTokenizer(java_tokenizer.JavaTokenizer, \"20210711_Java_github_java_deduplicated_vocabulary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm  import tqdm\n",
    "\n",
    "split_lines = [line.split(\"\\n\") for line in train_df[\"code\"]]\n",
    "\n",
    "train_df_new = pd.DataFrame(columns=[\"embedding\", \"godclass\"])\n",
    "\n",
    "def process_sample(sample):\n",
    "    sample_final = np.zeros(1024) \n",
    "\n",
    "    for line in sample:\n",
    "        inputs = fullTokenizer.convert_tokens_to_ids(fullTokenizer.tokenize(line))\n",
    "        if len(inputs) == 0:\n",
    "            continue  \n",
    "\n",
    "        inputs = tf.convert_to_tensor([inputs])  \n",
    "        outputs = model(inputs)  \n",
    "\n",
    "        sample_final += outputs[0][0][0].numpy()\n",
    "    print(\"one done :\\\"\")\n",
    "    return sample_final\n",
    "\n",
    "results = []\n",
    "with ProcessPoolExecutor() as executer:\n",
    "    futures = {executer.submit(process_sample, sample): i for i, sample in enumerate(split_lines)}\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=len(split_lines), desc=\"Processing Embeddings\"):\n",
    "        results.append(future.result())\n",
    "\n",
    "\n",
    "train_df_new[\"embedding\"] = results\n",
    "train_df_new[\"godclass\"] = train_df[\"godclass\"]\n",
    "\n",
    "train_df_new.to_csv(\"train_embeddings.csv\", index=False)\n",
    "\n",
    "print(\"Processing completed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "split_lines = [line.split('\\n') for line in train_df['code']]\n",
    "\n",
    "train_df_new = pd.DataFrame(columns = ['embedding', 'godclass'])\n",
    "\n",
    "for i, sample in enumerate(split_lines):\n",
    "    sample_final = np.zeros(1024)\n",
    "    for line in tqdm(sample):\n",
    "        with torch.no_grad():\n",
    "            inputs = fullTokenizer.convert_tokens_to_ids(fullTokenizer.tokenize(line))\n",
    "            if len(inputs) == 0:\n",
    "                continue\n",
    "            inputs = tf.convert_to_tensor([inputs])\n",
    "            outputs = model(inputs)\n",
    "            sample_final += outputs[0][0][0].numpy()\n",
    "\n",
    "    train_df_new = train_df_new.append({'embedding': sample_final, 'godclass': train_df['godclass'][i]}, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cubert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
